{"version":3,"file":"deGaulle.js","sources":["../js/src/index.js"],"sourcesContent":["//\r\n//\r\n//\r\n// https://stackoverflow.com/questions/59000552/how-to-print-stack-trace-with-reference-to-typescript-source-in-nest-js\r\nimport sourceMapSupport from 'source-map-support';\r\nsourceMapSupport.install();\r\nimport nomnom from '@gerhobbelt/nomnom';\r\nimport slug from '@gerhobbelt/slug';\r\nimport yaml from 'js-yaml';\r\nimport MarkDown from '@gerhobbelt/markdown-it';\r\nimport mdPluginCollective from 'markdown-it-dirty-dozen';\r\nimport { URL, fileURLToPath } from 'url';\r\n// see https://nodejs.org/docs/latest-v13.x/api/esm.html#esm_no_require_exports_module_exports_filename_dirname\r\nconst __filename = fileURLToPath(import.meta.url);\r\nconst __dirname = path.dirname(__filename);\r\nconst pkg = JSON.parse(fs.readFileSync(path.normalize(path.join(__dirname, '../package.json')), 'utf8'));\r\nimport cheerio from 'cheerio';\r\nimport glob from '@gerhobbelt/glob';\r\nimport gitignoreParser from '@gerhobbelt/gitignore-parser';\r\nimport assert from 'assert';\r\nimport path from 'path';\r\nimport fs from 'fs';\r\nlet DEBUG = 1;\r\nconst markdownTokens = {};\r\nconst config = {\r\n    docTreeBasedir: null,\r\n    destinationPath: null,\r\n    outputDirRelativePath: null\r\n};\r\nconst globDefaultOptions = {\r\n    debug: (DEBUG > 4),\r\n    matchBase: true,\r\n    silent: false,\r\n    strict: true,\r\n    realpath: true,\r\n    realpathCache: {},\r\n    follow: false,\r\n    dot: false,\r\n    mark: true,\r\n    nodir: true,\r\n    sync: false,\r\n    nounique: false,\r\n    nonull: false,\r\n    nosort: true,\r\n    nocase: true,\r\n    stat: false,\r\n    noprocess: false,\r\n    absolute: false,\r\n    maxLength: Infinity,\r\n    cache: {},\r\n    statCache: {},\r\n    symlinks: {},\r\n    cwd: null,\r\n    root: null,\r\n    nomount: false\r\n};\r\nexport default function main() {\r\n    nomnom.script('deGaulle');\r\n    nomnom\r\n        .command('build')\r\n        .option('debug', {\r\n        abbr: 'd',\r\n        flag: false,\r\n        'default': 0,\r\n        help: 'Print debugging info'\r\n    })\r\n        .option('config', {\r\n        abbr: 'c',\r\n        'default': 'config.js',\r\n        help: 'JS script file with custom handlers'\r\n    })\r\n        .option('output', {\r\n        abbr: 'o',\r\n        flag: false,\r\n        help: 'directory to write results to'\r\n    })\r\n        .callback(async function (opts, cmd) {\r\n        try {\r\n            await buildWebsite(opts, cmd);\r\n        }\r\n        catch (ex) {\r\n            console.error(`ERROR: ${ex.message}\\n\\nException:\\n`);\r\n            console.error(ex);\r\n            process.exit(5);\r\n        }\r\n    })\r\n        .help('build website from sources');\r\n    nomnom\r\n        .command('sanity')\r\n        .option('debug', {\r\n        abbr: 'd',\r\n        flag: false,\r\n        help: 'Print debugging info'\r\n    })\r\n        .option('config', {\r\n        abbr: 'c',\r\n        'default': 'config.js',\r\n        help: 'JS script file with custom handlers'\r\n    })\r\n        .option('outfile', {\r\n        abbr: 'o',\r\n        help: 'file to write results to'\r\n    })\r\n        .callback(function (opts, cmd) {\r\n        try {\r\n            sanityCheck(opts, cmd);\r\n        }\r\n        catch (ex) {\r\n            console.error(`ERROR: ${ex.message}\\n\\nException:\\n${ex}`);\r\n            process.exit(5);\r\n        }\r\n    })\r\n        .help('run the sanity tests');\r\n    nomnom\r\n        .nocommand()\r\n        .option('debug', {\r\n        abbr: 'd',\r\n        flag: false,\r\n        'default': 0,\r\n        help: 'Print debugging info'\r\n    })\r\n        .option('config', {\r\n        abbr: 'c',\r\n        'default': 'config.js',\r\n        help: 'JS script file with custom drivers'\r\n    })\r\n        .option('version', {\r\n        flag: true,\r\n        help: 'print version and exit',\r\n        callback: function () {\r\n            return `version ${pkg.version}`;\r\n        }\r\n    })\r\n        .callback(function (opts, cmd) {\r\n        try {\r\n            buildWebsite(opts, cmd);\r\n        }\r\n        catch (ex) {\r\n            console.error(`ERROR: ${ex.message}\\n\\nException:\\n${ex}`);\r\n            process.exit(5);\r\n        }\r\n    });\r\n    nomnom.parse();\r\n}\r\n// -- done --\r\nfunction unixify(path) {\r\n    return path.replace(/\\\\/g, '/');\r\n}\r\nfunction absSrcPath(rel) {\r\n    const p = path.join(config.docTreeBasedir, rel);\r\n    return unixify(path.resolve(p));\r\n}\r\nfunction absDstPath(rel) {\r\n    if (!config.destinationPath) {\r\n        throw new Error('Internal error: used too early');\r\n    }\r\n    const p = path.join(config.destinationPath, rel);\r\n    return unixify(path.resolve(p));\r\n}\r\nconst SANE_MAX_STRING_LENGTH = 2 * 120;\r\nfunction limitDebugOutput(str) {\r\n    if (str && str.length > SANE_MAX_STRING_LENGTH) {\r\n        str = `${str.slice(0, SANE_MAX_STRING_LENGTH - 20)}...\\n  ... (length: ${str.length})`;\r\n    }\r\n    return str;\r\n}\r\nfunction limitDebugOutput4Map(collection) {\r\n    if (collection instanceof Map) {\r\n        const rv = new Map();\r\n        collection.forEach((value, key) => {\r\n            rv.set(key, showRec(value));\r\n        });\r\n        return rv;\r\n    }\r\n    return collection;\r\n}\r\nfunction limitDebugOutput4Collection(allFiles) {\r\n    if (allFiles) {\r\n        const rv = {};\r\n        for (const type in allFiles) {\r\n            const m = allFiles[type];\r\n            rv[type] = limitDebugOutput4Map(m);\r\n        }\r\n        return rv;\r\n    }\r\n    return allFiles;\r\n}\r\nfunction showRec(rec) {\r\n    if (rec) {\r\n        const rv = Object.assign({}, rec);\r\n        for (const key in rv) {\r\n            const attr = rv[key];\r\n            if (typeof attr === 'string' && attr.length > SANE_MAX_STRING_LENGTH) {\r\n                rv[key] = limitDebugOutput(attr);\r\n            }\r\n        }\r\n        return rv;\r\n    }\r\n    return rec;\r\n}\r\nfunction slugify4Path(filePath) {\r\n    // slugify each path element individually so the '/' path separators don't get munched in the process!\r\n    let elems = unixify(filePath).split('/');\r\n    elems = elems.map(el => {\r\n        return slug(el, {\r\n            mode: 'filename',\r\n            replacement: '_'\r\n        });\r\n    });\r\n    return elems.join('/');\r\n}\r\nfunction slugify4TitleId(title) {\r\n    return slug(title, {\r\n        mode: 'pretty' // or should we use uslug?\r\n    });\r\n}\r\nfunction slugify4FileName(filePath, maxLength = 64) {\r\n    const hash = cyrb53hash(filePath);\r\n    const hashStr = hash.toString(16);\r\n    const basename = path.basename(filePath) + path.extname(filePath);\r\n    const nameslug = slug(basename, {\r\n        mode: 'path'\r\n    });\r\n    const dir = path.dirname(filePath);\r\n    const dirslug = slug(dir, {\r\n        mode: 'path'\r\n    });\r\n    const dirWords = dirslug.split('-');\r\n    const nameWords = nameslug.split('-');\r\n    let n = maxLength - hashStr.length;\r\n    const w = [];\r\n    let i = 0;\r\n    while (n >= 1 + nameWords[i].length && i < nameWords.length) {\r\n        n -= 1 + nameWords[i].length;\r\n        w.push(nameWords[i++]);\r\n    }\r\n    w.push(hashStr);\r\n    i = dirWords.length - 1;\r\n    while (n >= 1 + dirWords[i].length && i >= 0) {\r\n        n -= 1 + dirWords[i].length;\r\n        w.unshift(dirWords[i--]);\r\n    }\r\n    const sl = w.join('-');\r\n    return sl;\r\n}\r\n// remove dahes and _ underscores which represent spaces.\r\n//\r\n// underscores or dashes *around* a word are kept as-is:\r\n//    _laugh_ or -perish-\r\nfunction sanitizePathTotitle(str) {\r\n    return str\r\n        .replace(/(?:^|\\b)-(?:\\b|$)/g, ' ')\r\n        .replace(/(?:^|\\B)_(?:\\B|$)/g, ' ')\r\n        .trim();\r\n}\r\n// CYRB53 hash (NOT a secure hash)\r\n// as per https://stackoverflow.com/questions/7616461/generate-a-hash-from-string-in-javascript/52171480#52171480\r\n// (re `number` type: see https://spin.atomicobject.com/2018/11/05/using-an-int-type-in-typescript/ - deemed too much cost & effort right now)\r\nfunction cyrb53hash(str, seed = 0) {\r\n    let h1 = 0xdeadbeef ^ seed, h2 = 0x41c6ce57 ^ seed;\r\n    for (let i = 0, ch; i < str.length; i++) {\r\n        ch = str.charCodeAt(i);\r\n        h1 = Math.imul(h1 ^ ch, 2654435761);\r\n        h2 = Math.imul(h2 ^ ch, 1597334677);\r\n    }\r\n    h1 = Math.imul(h1 ^ (h1 >>> 16), 2246822507) ^ Math.imul(h2 ^ (h2 >>> 13), 3266489909);\r\n    h2 = Math.imul(h2 ^ (h2 >>> 16), 2246822507) ^ Math.imul(h1 ^ (h1 >>> 13), 3266489909);\r\n    return 4294967296 * (2097151 & h2) + (h1 >>> 0);\r\n}\r\nfunction readOptionalTxtConfigFile(rel) {\r\n    const p = absSrcPath(rel);\r\n    if (fs.existsSync(p)) {\r\n        const src = fs.readFileSync(p, 'utf8');\r\n        // - split into lines\r\n        // - filter out any lines which don't have an '='\r\n        // - split each line across the initial '=' in there.\r\n        // - turn this into a hash table?\r\n        const lines = src.split(/[\\r\\n]/g);\r\n        const linesarr = lines.filter((l) => l.trim().length > 1 && l.includes('=')).map((l) => {\r\n            let parts = l.split('=');\r\n            if (parts.length !== 2) {\r\n                throw new Error(`config line in ${rel} is expected to have only one '='`);\r\n            }\r\n            parts = parts.map((l) => l.trim());\r\n            return parts;\r\n        });\r\n        const rv = {};\r\n        linesarr.forEach((l) => {\r\n            rv[l[0]] = l[1];\r\n        });\r\n        return rv;\r\n    }\r\n    return {};\r\n}\r\n// name to path for wiki links\r\nfunction myCustomPageNamePostprocessor(spec) {\r\n    // clean up unwanted characters\r\n    spec = spec.replace(/ :: /g, '/');\r\n    spec = spec.replace(/ --* /g, '/');\r\n    spec = slugify4Path(spec);\r\n    return spec;\r\n}\r\n// this assumes `relativeDirPath` is normalized and does not contain ../ path segments anywhere.\r\n//\r\n// Returns a ./ or ../.../ path with trailing /\r\nfunction calculateRelativeJumpToBasePath(relativeDirPath) {\r\n    if (relativeDirPath === '.' || relativeDirPath == null) {\r\n        relativeDirPath = '';\r\n    }\r\n    relativeDirPath = relativeDirPath.replace(/\\/$/, ''); // remove possible trailing /\r\n    // count number of directories and generate a ../../../... path accordingly:\r\n    const destDepthArr = relativeDirPath.split('/');\r\n    const jumpbackPath = (new Array(destDepthArr.length + 1)).join('../');\r\n    return (relativeDirPath === '' ? './' : jumpbackPath);\r\n}\r\n// ripped from linkinator and then tweaked: which HTML tag has URLs in which attributes?\r\nconst linksAttr = {\r\n    background: ['body'],\r\n    cite: ['blockquote', 'del', 'ins', 'q'],\r\n    data: ['object'],\r\n    href: ['a', 'area', 'embed', 'link'],\r\n    icon: ['command'],\r\n    longdesc: ['frame', 'iframe'],\r\n    manifest: ['html'],\r\n    content: ['meta'],\r\n    poster: ['video'],\r\n    pluginspage: ['embed'],\r\n    pluginurl: ['embed'],\r\n    src: [\r\n        'audio',\r\n        'embed',\r\n        'frame',\r\n        'iframe',\r\n        'img',\r\n        'input',\r\n        'script',\r\n        'source',\r\n        'track',\r\n        'video'\r\n    ],\r\n    srcset: ['img', 'source']\r\n};\r\nfunction getLinks(document, baseFilePath) {\r\n    const $ = document;\r\n    let realBaseUrl;\r\n    const base = $('base[href]');\r\n    if (base.length) {\r\n        // only first <base> by specification\r\n        const htmlBaseUrl = base.first().attr('href');\r\n        console.log('processing page with <base> tag.', { htmlBaseUrl });\r\n        realBaseUrl = getBaseUrl(htmlBaseUrl, baseFilePath);\r\n        if (DEBUG >= 1)\r\n            console.log('getBaseUrl:', { htmlBaseUrl, baseFilePath, realBaseUrl });\r\n    }\r\n    else {\r\n        realBaseUrl = getBaseUrl('.', baseFilePath);\r\n        if (DEBUG >= 2)\r\n            console.log('getBaseUrl:', { dir: '.', baseFilePath, realBaseUrl });\r\n    }\r\n    const links = new Array();\r\n    const attrs = Object.keys(linksAttr);\r\n    for (const attr of attrs) {\r\n        const elements = linksAttr[attr].map(tag => `${tag}[${attr}]`).join(',');\r\n        $(elements).each((i, ele) => {\r\n            const element = ele;\r\n            if (!element.attribs) {\r\n                return;\r\n            }\r\n            const values = parseAttr(attr, element.attribs[attr]);\r\n            // ignore href properties for link tags where rel is likely to fail\r\n            const relValuesToIgnore = ['dns-prefetch', 'preconnect'];\r\n            if (element.tagName === 'link' &&\r\n                relValuesToIgnore.includes(element.attribs.rel)) {\r\n                return;\r\n            }\r\n            // Only for <meta content=\"\"> tags, only validate the url if\r\n            // the content actually looks like a url\r\n            if (element.tagName === 'meta' && element.attribs.content) {\r\n                try {\r\n                    new URL(element.attribs.content);\r\n                }\r\n                catch (e) {\r\n                    return;\r\n                }\r\n            }\r\n            for (const v of values) {\r\n                if (v) {\r\n                    const link = parseLink(v, realBaseUrl, element, attr);\r\n                    if (!v.startsWith('https://')) {\r\n                        if (DEBUG >= 2)\r\n                            console.log('parseLink:', { v, realBaseUrl, result: link.url });\r\n                    }\r\n                    links.push(link);\r\n                }\r\n            }\r\n        });\r\n    }\r\n    return links;\r\n}\r\nfunction getBaseUrl(htmlBaseUrl, oldBaseUrl) {\r\n    if (isAbsoluteUrl(htmlBaseUrl)) {\r\n        return htmlBaseUrl;\r\n    }\r\n    try {\r\n        const url = new URL(htmlBaseUrl, oldBaseUrl);\r\n        url.search = '';\r\n        url.hash = '';\r\n        return url.href;\r\n    }\r\n    catch (ex) {\r\n        // merge paths:\r\n        if (!path.isAbsolute(htmlBaseUrl)) {\r\n            htmlBaseUrl = path.join(oldBaseUrl, htmlBaseUrl);\r\n            if (!path.isAbsolute(htmlBaseUrl)) {\r\n                htmlBaseUrl = path.join('/', htmlBaseUrl);\r\n            }\r\n        }\r\n        // URL class constructor automatically does URL path normalization:\r\n        //\r\n        // http://x.ccom/a/b/c/../d.html --> path: /a/b/d.html\r\n        const url = new URL('http://localhost' + unixify(htmlBaseUrl));\r\n        url.search = '';\r\n        url.hash = '';\r\n        return url.href;\r\n    }\r\n}\r\nfunction isAbsoluteUrl(url) {\r\n    // Don't match Windows paths\r\n    if (/^[a-zA-Z]:\\\\/.test(url)) {\r\n        return false;\r\n    }\r\n    // Scheme: https://tools.ietf.org/html/rfc3986#section-3.1\r\n    // Absolute URL: https://tools.ietf.org/html/rfc3986#section-4.3\r\n    return /^[a-zA-Z][a-zA-Z\\d+\\-.]*:/.test(url);\r\n}\r\nfunction parseAttr(name, value) {\r\n    switch (name) {\r\n        case 'srcset':\r\n            return value\r\n                .split(',')\r\n                .map((pair) => pair.trim().split(/\\s+/)[0]);\r\n        default:\r\n            return [value];\r\n    }\r\n}\r\nfunction parseLink(link, baseUrl, node, attr) {\r\n    // strip off any 'file://' prefix first:\r\n    if (link.startsWith('file://')) {\r\n        link = link.slice(7);\r\n    }\r\n    // remove Windows drive letters from 'absolute' paths:\r\n    link = link.replace(/^\\/?[a-zA-Z][:]\\//, '');\r\n    try {\r\n        const url = new URL(link, baseUrl);\r\n        //url.hash = '';\r\n        return { node, attr, link, url, href: url.href };\r\n    }\r\n    catch (error) {\r\n        console.log('parseLink error', { error, link, baseUrl, attr });\r\n        return { node, attr, link, error, href: null };\r\n    }\r\n}\r\nasync function loadConfigScript(configScript) {\r\n    if (configScript) {\r\n        // https://stackoverflow.com/questions/42453683/how-to-reject-in-async-await-syntax\r\n        if (DEBUG >= 1)\r\n            console.log(`loadConfigScript(${configScript})`);\r\n        if (!path.isAbsolute(configScript)) {\r\n            // make sure `import` sees a './'-based relative path, or it barf a hairball as it will treat the base directory as a package identifier instead!\r\n            configScript = unixify(path.join(process.cwd(), configScript));\r\n        }\r\n        if (DEBUG >= 1)\r\n            console.log(`loadConfigScript(prepped: '${configScript}')`);\r\n        try {\r\n            const processors = await import('file://' + configScript);\r\n            throw 1;\r\n            return processors;\r\n        }\r\n        catch (err) {\r\n            console.error('######## ERROR: ', err);\r\n            //throw new AggregateError([ err ], `Cannot open/load config script file '${configScript}'`);\r\n            throw new Error(`Cannot open/load config script file '${configScript}'. Error: ${err}`);\r\n        }\r\n    }\r\n    else {\r\n        return new Promise((resolve, reject) => {\r\n            const processors = {\r\n                default: function nil() {\r\n                    // no op\r\n                },\r\n            };\r\n            resolve(processors);\r\n        });\r\n    }\r\n}\r\nasync function sanityCheck(opts, command) {\r\n    console.log(`sanityCheck: command: ${command || '<no-command>'}, opts: ${JSON.stringify(opts, null, 2)}`);\r\n    DEBUG = Math.max(DEBUG, Number.isFinite(+opts.debug) ? +opts.debug : opts.debug ? 1 : 0);\r\n    console.log('DEBUG = ', DEBUG);\r\n    return new Promise((resolve, reject) => {\r\n        resolve(0);\r\n    });\r\n}\r\nasync function globDirectory(pathWithWildCards, globConfig) {\r\n    assert(pathWithWildCards != null);\r\n    if (DEBUG >= 8)\r\n        console.log('scanPath:', pathWithWildCards);\r\n    return new Promise((resolve, reject) => {\r\n        glob(pathWithWildCards, globConfig, function processGlobResults(err, files) {\r\n            if (err) {\r\n                reject(new Error(`glob scan error: ${err}`));\r\n                return;\r\n            }\r\n            if (DEBUG >= 1)\r\n                console.log(` --> scan: ${JSON.stringify(files, null, 2)}`);\r\n            resolve(files);\r\n        });\r\n    });\r\n}\r\nasync function buildWebsite(opts, command) {\r\n    console.log(`buildWebsite: command: ${command || '<no-command>'}, opts: ${JSON.stringify(opts, null, 2)}`);\r\n    DEBUG = Math.max(DEBUG, Number.isFinite(+opts.debug) ? +opts.debug : opts.debug ? 1 : 0);\r\n    console.log('DEBUG = ', DEBUG);\r\n    const paths = opts._.slice(command ? 1 : 0);\r\n    const minPathsCount = 1;\r\n    console.log('SOURCE PATHS = ', paths);\r\n    if (!paths || paths.length < minPathsCount) {\r\n        throw new Error('Must specify at least one file path as starting point. None were specified.');\r\n    }\r\n    // load the config script, iff it exists:\r\n    let configScript = opts.config;\r\n    // look for config script in this order:\r\n    // - source path #1 /.deGaulle/\r\n    // - current directory /.deGaulle/\r\n    // - source path #1 /\r\n    // - current directory /\r\n    //\r\n    // we look at `source path #1/` relatively *late* in the game to prevent\r\n    // clashes with a config.js that might be located there for other purposes,\r\n    // e.g. as part of the website itself.\r\n    //\r\n    if (!path.isAbsolute(configScript)) {\r\n        const searchDirList = [\r\n            unixify(path.join(paths[0], '.deGaulle')),\r\n            unixify(path.join(process.cwd(), '.deGaulle')),\r\n            unixify(paths[0]),\r\n            unixify(process.cwd()),\r\n        ];\r\n        for (let p of searchDirList) {\r\n            let cfgpath = unixify(path.join(p, configScript));\r\n            if (DEBUG >= 1)\r\n                console.log(`Looking in ${cfgpath} for CONFIG FILE.`);\r\n            if (fs.existsSync(cfgpath)) {\r\n                configScript = cfgpath;\r\n                break;\r\n            }\r\n        }\r\n    }\r\n    let processors = null;\r\n    try {\r\n        processors = await loadConfigScript(configScript);\r\n    }\r\n    catch (err) {\r\n        console.error('##### ERROR while importing config script. (Will continue with a default script.)\\nError: ', err);\r\n        processors = await loadConfigScript(null);\r\n    }\r\n    if (DEBUG >= 1)\r\n        console.log('config/processors STRUCT:', processors);\r\n    assert(processors.default != null);\r\n    assert(typeof processors.default === 'function', `configScript \"${configScript}\" is supposed to define at least a 'default' processor function`);\r\n    if (DEBUG >= 1)\r\n        console.log('configScript.processors = ', processors);\r\n    let firstEntryPointPath = paths[0];\r\n    // make sure we start with an absolute path; everything will derive off this one.\r\n    if (!path.isAbsolute(firstEntryPointPath)) {\r\n        firstEntryPointPath = path.join(process.cwd(), firstEntryPointPath);\r\n    }\r\n    firstEntryPointPath = unixify(path.normalize(firstEntryPointPath));\r\n    if (DEBUG >= 1)\r\n        console.log('firstEntryPointPath = ', firstEntryPointPath);\r\n    let entryStats = fs.lstatSync(firstEntryPointPath);\r\n    throw 2;\r\n    if (entryStats && entryStats.isDirectory()) {\r\n        // check if any of the default entry points exist:\r\n        // - index.md\r\n        // - index.html\r\n        // - README.md\r\n        let indexFile;\r\n        let indexFilePriority = 0;\r\n        let basePath = firstEntryPointPath;\r\n        basePath = unixify(basePath);\r\n        let scanPath = path.join(firstEntryPointPath, '{index,readme}.{md,htm,html}');\r\n        scanPath = unixify(scanPath);\r\n        if (DEBUG >= 8)\r\n            console.log('scanPath:', scanPath);\r\n        const globConfig = Object.assign({}, globDefaultOptions, {\r\n            nodir: true,\r\n            cwd: basePath\r\n        });\r\n        assert(scanPath != null);\r\n        const files = await globDirectory(scanPath, globConfig);\r\n        if (DEBUG >= 3)\r\n            console.log(`root point DIR --> scan: ${JSON.stringify(files, null, 2)}`);\r\n        const filelist = files || [];\r\n        for (const f of filelist) {\r\n            if (DEBUG >= 10)\r\n                console.log('Loop!', { f });\r\n            const basename = path.basename(f.toLowerCase());\r\n            if (DEBUG >= 7)\r\n                console.log('Can this serve as root?', basename);\r\n            switch (basename) {\r\n                case 'index.md':\r\n                    if (indexFilePriority < 10) {\r\n                        indexFilePriority = 10;\r\n                        indexFile = f;\r\n                    }\r\n                    break;\r\n                case 'index.htm':\r\n                case 'index.html':\r\n                    if (indexFilePriority < 5) {\r\n                        indexFilePriority = 5;\r\n                        indexFile = f;\r\n                    }\r\n                    break;\r\n                case 'readme.md':\r\n                    if (DEBUG >= 7)\r\n                        console.log('Hit!', basename);\r\n                    if (indexFilePriority < 1) {\r\n                        indexFilePriority = 1;\r\n                        indexFile = f;\r\n                    }\r\n                    if (DEBUG >= 7)\r\n                        console.log('Continue!', indexFile);\r\n                    break;\r\n                default:\r\n                    if (DEBUG >= 1)\r\n                        console.log('WUT?!', basename);\r\n                    break;\r\n            }\r\n        }\r\n        if (DEBUG >= 10)\r\n            console.log('Loop end!', indexFile);\r\n        if (DEBUG >= 3)\r\n            console.log('root scan -> indexFile', indexFile);\r\n        if (indexFile) {\r\n            firstEntryPointPath = unixify(path.resolve(indexFile));\r\n            if (DEBUG >= 1)\r\n                console.log('root scan -> firstEntryPointPath', firstEntryPointPath);\r\n            entryStats = fs.lstatSync(firstEntryPointPath);\r\n        }\r\n        else {\r\n            throw new Error(`Could not find a default entry point file (index.md, index.html or README.md) in the entry point directory ${firstEntryPointPath} (${scanPath})`);\r\n        }\r\n    }\r\n    if (!entryStats) {\r\n        throw new Error(`entry point does not exist: ${firstEntryPointPath}`);\r\n    }\r\n    if (!entryStats.isFile()) {\r\n        throw new Error(`entry point is not a file: ${firstEntryPointPath}`);\r\n    }\r\n    config.docTreeBasedir = path.dirname(firstEntryPointPath);\r\n    if (DEBUG >= 1)\r\n        console.log('docTreeBasedir = ', config.docTreeBasedir);\r\n    let outputDirPath = paths[1] || path.join(config.docTreeBasedir, (!config.docTreeBasedir.endsWith('docs') ? '../docs' : '../' + path.basename(config.docTreeBasedir) + '-output'));\r\n    // make sure we start with an absolute path; everything will derived off this one.\r\n    if (!path.isAbsolute(outputDirPath)) {\r\n        outputDirPath = path.join(process.cwd(), outputDirPath);\r\n    }\r\n    outputDirPath = unixify(path.normalize(outputDirPath));\r\n    if (DEBUG >= 1)\r\n        console.log('outputDirPath = ', outputDirPath);\r\n    config.destinationPath = outputDirPath;\r\n    config.outputDirRelativePath = unixify(path.relative(config.docTreeBasedir, config.destinationPath));\r\n    if (DEBUG >= 2)\r\n        console.log('config:', config);\r\n    const rv_mapping_def = {\r\n        markdown: [\r\n            'md',\r\n            'markdown'\r\n        ],\r\n        html: [\r\n            'html',\r\n            'htm'\r\n        ],\r\n        js: [\r\n            'js',\r\n            'mjs',\r\n            'ejs',\r\n            'cjs',\r\n            'ts',\r\n            'coffee'\r\n        ],\r\n        css: [\r\n            'css',\r\n            'scss',\r\n            'less',\r\n            'styl',\r\n            'stylus'\r\n        ],\r\n        image: [\r\n            'png',\r\n            'gif',\r\n            'jpg',\r\n            'jpeg',\r\n            'tiff',\r\n            'bmp',\r\n            'svg',\r\n            'psd',\r\n            'ai',\r\n            'webp'\r\n        ],\r\n        font: [\r\n            'ttf',\r\n            'otf',\r\n            'eot',\r\n            'woff2'\r\n        ],\r\n        movie: [\r\n            'mkv',\r\n            'mp4',\r\n            'avi',\r\n            'mov',\r\n            'flv',\r\n            'webm'\r\n        ],\r\n        archive: [\r\n            'zip',\r\n            'rar',\r\n            'gz',\r\n            'bz2',\r\n            '7z'\r\n        ],\r\n        distro: [\r\n            'exe',\r\n            'msi'\r\n        ]\r\n    };\r\n    const rv_mapping_bin_content = {\r\n        png: true,\r\n        gif: true,\r\n        jpg: true,\r\n        jpeg: true,\r\n        tiff: true,\r\n        bmp: true,\r\n        svg: false,\r\n        psd: true,\r\n        ai: true,\r\n        mkv: true,\r\n        mp4: true,\r\n        avi: true,\r\n        mov: true,\r\n        flv: true,\r\n        webm: true,\r\n        webp: true,\r\n        zip: true,\r\n        rar: true,\r\n        gz: true,\r\n        bz2: true,\r\n        '7z': true,\r\n        exe: true,\r\n        msi: true\r\n    };\r\n    const rv_mapping = new Map();\r\n    for (const n in rv_mapping_def) {\r\n        const a = rv_mapping_def[n];\r\n        if (DEBUG >= 4)\r\n            console.log('key n', { n, a });\r\n        for (const b of a) {\r\n            if (DEBUG >= 4)\r\n                console.log('map n -> b', { n, b });\r\n            rv_mapping.set('.' + b, n);\r\n        }\r\n    }\r\n    if (DEBUG >= 3)\r\n        console.log('######################### mapping ##########################\\n', rv_mapping, '\\n###########################################');\r\n    // now find all gitignore files, load them and use them to find out which DIRECTORIES\r\n    // we'll have to ignore at the very least: this should speed up the later global glob\r\n    // action quite a lot, as we can them specify a solid list of directories to ignore\r\n    // as part of its search options.\r\n    //\r\n    // Produces an object carrying an array of directories to ignore, plus an array listing\r\n    // all gitignore files, plus a hash table which carries the parsed gitignore files\r\n    // for further use.\r\n    //\r\n    // Each directory/file record has this format:\r\n    //\r\n    // {\r\n    //   path,        -- full path to file\r\n    //   name         -- filename\r\n    //   relativePath --  relative path to config.docTreeBasedir\r\n    // }\r\n    //\r\n    function mkIgnoreFileRecord(filePath) {\r\n        const f = unixify(path.resolve(filePath));\r\n        const fname = path.basename(f);\r\n        const el = {\r\n            path: f,\r\n            name: fname,\r\n            relativePath: unixify(path.relative(config.docTreeBasedir, f))\r\n        };\r\n        return el;\r\n    }\r\n    async function collectAllIgnoreFilesInDirectory(baseDirPath) {\r\n        const basePath = unixify(path.resolve(baseDirPath));\r\n        let scanPath = path.join(basePath, '.*ignore');\r\n        scanPath = unixify(scanPath);\r\n        if (DEBUG >= 8)\r\n            console.log('scanPath:', scanPath);\r\n        const globConfig = Object.assign({}, globDefaultOptions, {\r\n            dot: true,\r\n            nodir: true\r\n        });\r\n        // Gather all ignore files, collect their content (they are all\r\n        // assumed to have the same gitignore format anyway) and feed that\r\n        // to the gitignore compiler:\r\n        const files = await globDirectory(scanPath, globConfig);\r\n        const rv = {\r\n            filesToProcess: [],\r\n            directoriesProcessed: [],\r\n            directoriesToIgnore: [],\r\n            ignoreFilePaths: [],\r\n            ignoreInfo: null\r\n        };\r\n        const ignoreContent = [];\r\n        for (const p of files || []) {\r\n            const el = mkIgnoreFileRecord(p);\r\n            ignoreContent.push(fs.readFileSync(el.path, 'utf8'));\r\n            rv.ignoreFilePaths.push(el);\r\n        }\r\n        // Now that we have collected all ignore files' content, we can\r\n        // check if there's anything useful in there and compile that\r\n        // for further use later on.\r\n        const str = ignoreContent.join('\\n\\n\\n').trim();\r\n        if (str.length > 0) {\r\n            // at least there's something to parse today...\r\n            const gitignoreData = gitignoreParser.compile(str);\r\n            const rec = {\r\n                directoryPath: basePath,\r\n                compiledIgnoreData: gitignoreData,\r\n                parentRecord: null // we don't know yet if this directory has a parent with gitignore data...\r\n            };\r\n            rv.ignoreInfo = rec;\r\n        }\r\n        return rv;\r\n    }\r\n    function isPathAcceptedByIgnoreRecords(path, ignoreRecord) {\r\n        if (!ignoreRecord || !ignoreRecord.compiledIgnoreData) {\r\n            return true;\r\n        }\r\n        // gitignore rules: when a child gitignore file has something to say\r\n        // about a path, then we do not bother the parent. (Override By Child)\r\n        if (ignoreRecord.compiledIgnoreData.inspects(path)) {\r\n            return ignoreRecord.compiledIgnoreData.accepts(path);\r\n        }\r\n        if (ignoreRecord.parentRecord) {\r\n            return isPathAcceptedByIgnoreRecords(path, ignoreRecord.parentRecord);\r\n        }\r\n        // accept by default\r\n        return true;\r\n    }\r\n    async function collectAllExceptIgnoredInDirectory(baseDirPath, parentIgnores) {\r\n        assert(baseDirPath != null);\r\n        const basePath = path.resolve(baseDirPath);\r\n        let scanPath = path.join(basePath, '*');\r\n        scanPath = unixify(scanPath);\r\n        if (DEBUG >= 8)\r\n            console.log('scanPath:', scanPath);\r\n        const globConfig = Object.assign({}, globDefaultOptions, {\r\n            nodir: false,\r\n            mark: true\r\n        });\r\n        assert(scanPath != null);\r\n        const files = await globDirectory(scanPath, globConfig);\r\n        // collect all the local ignore files.\r\n        const dirscanInfo = await collectAllIgnoreFilesInDirectory(basePath);\r\n        let activeIgnoreRecord = dirscanInfo.ignoreInfo;\r\n        // hook up the parent if there's any\r\n        if (activeIgnoreRecord && parentIgnores) {\r\n            activeIgnoreRecord.parentRecord = parentIgnores;\r\n        }\r\n        // otherwise, when we have no ignore record of our own, use the parent as-is\r\n        else if (!activeIgnoreRecord) {\r\n            activeIgnoreRecord = parentIgnores;\r\n        }\r\n        const directoriesToScan = [];\r\n        for (const p of files || []) {\r\n            // skip the entries which are NOT directories?\r\n            // Nah, keep them around for the ignore check that comes next:\r\n            const isDir = p.endsWith('/');\r\n            const d = mkIgnoreFileRecord(p);\r\n            const ok = isPathAcceptedByIgnoreRecords(d.path, activeIgnoreRecord);\r\n            // NOTE: the ignore files are themselves *ignored by default*:\r\n            // dot-files are all ignored always.\r\n            if (DEBUG >= 8)\r\n                console.log(`isPathAcceptedByIgnoreRecords(\"${d.path}\") --> pass: ${ok}, isDir: ${isDir}`);\r\n            // when the entry is to be ignored, we add it to the list:\r\n            if (!ok) {\r\n                dirscanInfo.directoriesToIgnore.push(d);\r\n            }\r\n            else if (isDir) {\r\n                directoriesToScan.push(d.path);\r\n            }\r\n            else {\r\n                dirscanInfo.filesToProcess.push(d);\r\n            }\r\n        }\r\n        dirscanInfo.directoriesProcessed.push(basePath);\r\n        // now go and investigate the okay-ed subdirectories:\r\n        for (const p of directoriesToScan) {\r\n            const rv = await collectAllExceptIgnoredInDirectory(p, activeIgnoreRecord);\r\n            dirscanInfo.filesToProcess = dirscanInfo.filesToProcess.concat(rv.filesToProcess);\r\n            dirscanInfo.directoriesToIgnore = dirscanInfo.directoriesToIgnore.concat(rv.directoriesToIgnore);\r\n            dirscanInfo.directoriesProcessed = dirscanInfo.directoriesProcessed.concat(rv.directoriesProcessed);\r\n            dirscanInfo.ignoreFilePaths = dirscanInfo.ignoreFilePaths.concat(rv.ignoreFilePaths);\r\n        }\r\n        return dirscanInfo;\r\n    }\r\n    // now scan the entire tree: collect potential files for comparison & treatment\r\n    //\r\n    // Produces an array of categories, which each are an array of file records,\r\n    // where each file record has this format:\r\n    //\r\n    // {\r\n    //   path,        -- full path to file\r\n    //   nameLC       -- lowercased filename\r\n    //   ext          -- lowercased filename extension\r\n    //   relativePath --  relative path to config.docTreeBasedir\r\n    // }\r\n    //\r\n    async function collectAllFiles() {\r\n        let basePath = config.docTreeBasedir;\r\n        basePath = unixify(basePath);\r\n        const files = await collectAllExceptIgnoredInDirectory(basePath, null);\r\n        if (DEBUG >= 2)\r\n            console.log(`root point DIR --> scan: ${JSON.stringify(files, null, 2)}`);\r\n        const rv = {\r\n            markdown: new Map(),\r\n            html: new Map(),\r\n            css: new Map(),\r\n            js: new Map(),\r\n            image: new Map(),\r\n            movie: new Map(),\r\n            archive: new Map(),\r\n            distro: new Map(),\r\n            misc: new Map(),\r\n            _: new Map()\r\n        };\r\n        for (const rec of files.filesToProcess || []) {\r\n            AddFileToCollection(rec, rv);\r\n        }\r\n        return rv;\r\n    }\r\n    function AddFileToCollection(fileInfo, collection) {\r\n        // check if the file is to be 'ignored' and treated as a static binary asset:\r\n        let special = false;\r\n        const fpath = fileInfo.path;\r\n        const fname = fileInfo.name;\r\n        if (!fname) {\r\n            console.error('AddFileToCollection:', fileInfo);\r\n        }\r\n        ['CNAME', '.nojekyll'].forEach((f) => {\r\n            if (typeof f === 'string' && fname.endsWith(f)) {\r\n                special = true;\r\n            }\r\n            else if (f instanceof RegExp && f.test(fname)) {\r\n                special = true;\r\n            }\r\n        });\r\n        let ext = path.extname(fname).toLowerCase();\r\n        if (special) {\r\n            ext = '';\r\n        }\r\n        const el = {\r\n            path: fpath,\r\n            name: fname,\r\n            nameLC: fname.toLowerCase(),\r\n            ext: ext,\r\n            relativePath: unixify(path.relative(config.docTreeBasedir, fpath)),\r\n            destinationRelPath: null,\r\n            relativeJumpToBasePath: null,\r\n            RawContent: null,\r\n            contentIsBinary: rv_mapping_bin_content[ext] || special,\r\n            includedInTOC: 0,\r\n            mappingKey: null\r\n        };\r\n        const cat = rv_mapping.get(ext) || 'misc';\r\n        collection[cat].set(fpath, el);\r\n        collection._.set(fpath, el);\r\n    }\r\n    // async invocation, but don't wait for it yet:\r\n    const scan = collectAllFiles();\r\n    const md = MarkDown({\r\n        // Enable HTML tags in source\r\n        html: true,\r\n        // Use '/' to close single tags (<br />).\r\n        xhtmlOut: false,\r\n        // Convert '\\n' in paragraphs into <br>\r\n        breaks: false,\r\n        // CSS language prefix for fenced blocks. Can be useful for external highlighters.\r\n        langPrefix: 'language-',\r\n        // Autoconvert URL-like text to links\r\n        linkify: true,\r\n        // highSecurity:\r\n        // - false:           lower protection against XSS/Unicode-Homologue/etc. attacks via the input MarkDown.\r\n        //                    This setting assumes you own or at least trust the Markdown\r\n        //                    being fed to MarkDonw-It. The result is a nicer render.\r\n        // - true (default):  maximum protection against XSS/Unicode-Homologue/etc. attacks via the input MarkDown.\r\n        //                    This is the default setting and assumes you have no control or absolute trust in the Markdown\r\n        //                    being fed to MarkDonw-It. Use this setting when using markdown-it as part of a forum or other\r\n        //                    website where more-or-less arbitrary users can enter and feed any MarkDown to markdown-it.\r\n        //\r\n        // See https://en.wikipedia.org/wiki/Internationalized_domain_name for details on homograph attacks, for example.\r\n        highSecurity: false,\r\n        // Enable some language-neutral replacement + quotes beautification\r\n        typographer: true,\r\n        // Double + single quotes replacement pairs, when typographer enabled,\r\n        // and smartquotes on. Could be either a String or an Array.\r\n        //\r\n        // For example, you can use '«»„“' for Russian, '„“‚‘' for German,\r\n        // and ['«\\xA0', '\\xA0»', '‹\\xA0', '\\xA0›'] for French (including nbsp).\r\n        quotes: '“”‘’',\r\n        // Highlighter function. Should return escaped HTML,\r\n        // or '' if the source string is not changed and should be escaped externally.\r\n        // If result starts with <pre... internal wrapper is skipped.\r\n        highlight: function () {\r\n            console.error('highligh callback invoked!');\r\n            return '';\r\n        } // Configure default attributes for given tags\r\n        //default_attributes: { a: [['rel', 'nofollow']] }\r\n    });\r\n    // augment the md instance for use with the markdown_it_include plugin:\r\n    //md.getIncludeRootDir = ...\r\n    if (DEBUG >= 2)\r\n        console.log('setting up markdown-it:', mdPluginCollective, typeof mdPluginCollective.use_dirty_dozen);\r\n    mdPluginCollective.use_dirty_dozen(md, {\r\n        abbr: {\r\n            abbreviations: readOptionalTxtConfigFile('.deGaulle/abbr-abbreviations.txt'),\r\n            links: readOptionalTxtConfigFile('.deGaulle/abbr-links.txt'),\r\n            emphasis: readOptionalTxtConfigFile('.deGaulle/abbr-emphasis-phrases.txt')\r\n        },\r\n        attrs: true,\r\n        anchor: {\r\n            permalink: true,\r\n            permalinkBefore: true,\r\n            permalinkSymbol: `\n        <svg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\">\n          <path fill-rule=\"evenodd\" d=\"M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z\"></path>\n        </svg>`,\r\n            slugify: function (el_title) {\r\n                return slugify4TitleId(el_title);\r\n            }\r\n        },\r\n        //githubHeadings: false,\r\n        footnote: {\r\n            atDocumentEnd: false\r\n        },\r\n        furigana: true,\r\n        frontMatter: {\r\n            callback: function (meta, token, state) {\r\n                try {\r\n                    const doc = yaml.load(meta);\r\n                    token.meta = doc; // override token.meta with the parsed object\r\n                    console.log('parsed YAML:', doc);\r\n                }\r\n                catch (ex) {\r\n                    console.error('error parsing frontmatter YAML:', ex);\r\n                    throw ex;\r\n                }\r\n            }\r\n        },\r\n        include: {\r\n            root: '/includes/',\r\n            getRootDir: (options, state, startLine, endLine) => {\r\n                if (DEBUG >= 2)\r\n                    console.log('includes:: state:', { state });\r\n                return state.env.getIncludeRootDir(options, state, startLine, endLine);\r\n            }\r\n        },\r\n        title: {\r\n            level: 0 // grab the first H1/H2/... that we encounter\r\n        },\r\n        wikilinks: {\r\n            postProcessPageName: function (pageName) {\r\n                const rv = myCustomPageNamePostprocessor(pageName);\r\n                if (DEBUG >= 2)\r\n                    console.log('wikilink transform:', { 'in': pageName, out: rv });\r\n                return rv;\r\n            }\r\n        },\r\n        // [[toc]]\r\n        tableOfContents: false,\r\n        // @[toc](Title)\r\n        toc: true,\r\n        // @[toc]               -- no title...\r\n        tocAndAnchor: false,\r\n        // ${toc} | [[toc]]     -- but we removed that last version by specifying a custom placeholder here:\r\n        tocDoneRight: {\r\n            placeholder: '(\\\\$\\\\{toc\\\\})',\r\n            slugify: function (el_title) {\r\n                return slugify4TitleId(el_title);\r\n            }\r\n        }\r\n    });\r\n    const allFiles = await scan;\r\n    if (DEBUG >= 2)\r\n        console.log('!!!!!!!!!!!!!!!! allFiles:', limitDebugOutput4Collection(allFiles));\r\n    if (!allFiles.markdown.get(firstEntryPointPath) && !allFiles.html.get(firstEntryPointPath)) {\r\n        throw new Error(`root file '${firstEntryPointPath}' is supposed to be part of the website`);\r\n    }\r\n    if (0) {\r\n        console.log(`processing root file: ${firstEntryPointPath}...`);\r\n        const specRec = await compileMD(firstEntryPointPath, md, allFiles);\r\n        if (DEBUG >= 10)\r\n            console.log('specRec:', showRec(specRec));\r\n    }\r\n    console.log('processing/loading site files...');\r\n    // now process the HTML, MD, CSS, JS and other 'fixed assets' files:\r\n    //\r\n    // [css, js, image, movie, misc, _]\r\n    for (const type in allFiles) {\r\n        switch (type) {\r\n            case '_':\r\n                continue;\r\n            case 'markdown':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        // as these pages will be rendered to HTML, they'll receive the html extension:\r\n                        entry.destinationRelPath = slugify4Path(entry.relativePath.slice(0, entry.relativePath.length - entry.ext.length)) + '.html';\r\n                        entry.relativeJumpToBasePath = calculateRelativeJumpToBasePath(path.dirname(entry.destinationRelPath));\r\n                        if (DEBUG >= 5)\r\n                            console.log('!!!!!!!!!!!!!!!!!!!!!!!! markdown file record:', showRec(entry));\r\n                        const specRec2 = await compileMD(key, md, allFiles);\r\n                        if (DEBUG >= 3)\r\n                            console.log('specRec:', showRec(specRec2));\r\n                        assert.strictEqual(specRec2, entry);\r\n                    }\r\n                }\r\n                continue;\r\n            case 'html':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        // It doesn't matter whether these started out as .htm or .html files: we output them as .html files anyway:\r\n                        entry.destinationRelPath = slugify4Path(entry.relativePath.slice(0, entry.relativePath.length - entry.ext.length)) + '.html';\r\n                        entry.relativeJumpToBasePath = calculateRelativeJumpToBasePath(path.dirname(entry.destinationRelPath));\r\n                        if (DEBUG >= 5)\r\n                            console.log('!!!!!!!!!!!!!!!!!!!!!!!! HTML file record:', showRec(entry));\r\n                        const specRec2 = await loadHTML(key, allFiles);\r\n                        if (DEBUG >= 3)\r\n                            console.log('specRec:', showRec(specRec2));\r\n                        assert.strictEqual(specRec2, entry);\r\n                    }\r\n                }\r\n                continue;\r\n            case 'css':\r\n            case 'js':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        entry.destinationRelPath = slugify4Path(entry.relativePath.slice(0, entry.relativePath.length - entry.ext.length)) + entry.ext;\r\n                        entry.relativeJumpToBasePath = calculateRelativeJumpToBasePath(path.dirname(entry.destinationRelPath));\r\n                        if (DEBUG >= 5)\r\n                            console.log(`!!!!!!!!!!!!!!!!!!!!!!!! Type [${type}] file record:`, showRec(entry));\r\n                        const specRec2 = await loadFixedAssetTextFile(key, allFiles, collection);\r\n                        if (DEBUG >= 3)\r\n                            console.log('specRec:', showRec(specRec2));\r\n                        assert.strictEqual(specRec2, entry);\r\n                    }\r\n                }\r\n                continue;\r\n            default:\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        entry.destinationRelPath = slugify4Path(entry.relativePath.slice(0, entry.relativePath.length - entry.ext.length)) + entry.ext;\r\n                        entry.relativeJumpToBasePath = calculateRelativeJumpToBasePath(path.dirname(entry.destinationRelPath));\r\n                        if (DEBUG >= 5)\r\n                            console.log(`!!!!!!!!!!!!!!!!!!!!!!!! Type [${type}] file record:`, showRec(entry));\r\n                        const specRec2 = await loadFixedAssetBinaryFile(key, allFiles, collection);\r\n                        if (DEBUG >= 3)\r\n                            console.log('specRec:', showRec(specRec2));\r\n                        assert.strictEqual(specRec2, entry);\r\n                    }\r\n                }\r\n                continue;\r\n        }\r\n    }\r\n    // now's the time to match the links in the generated content and do some linkage reporting alongside:\r\n    //\r\n    if (DEBUG >= 2)\r\n        console.log('>>>>>>>>>>>>>>>>>>>> allFiles:', limitDebugOutput4Collection(allFiles));\r\n    if (DEBUG >= 1)\r\n        console.log('markdown AST token types:', Object.keys(markdownTokens).sort());\r\n    console.log('tracing site files...');\r\n    // now trace the access graph:\r\n    //\r\n    // [css, js, image, movie, misc, _]\r\n    for (const type in allFiles) {\r\n        switch (type) {\r\n            case '_':\r\n                continue;\r\n            case 'markdown':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        //entry.destinationRelPath\r\n                    }\r\n                }\r\n                continue;\r\n            case 'html':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        // It doesn't matter whether these started out as .htm or .html files: we output them as .html files anyway:\r\n                        //entry.destinationRelPath\r\n                    }\r\n                }\r\n                continue;\r\n            case 'css':\r\n            case 'js':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        //entry.destinationRelPath\r\n                    }\r\n                }\r\n                continue;\r\n            default:\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        //entry.destinationRelPath\r\n                    }\r\n                }\r\n                continue;\r\n        }\r\n    }\r\n    console.log('updating/patching site files...');\r\n    // now patch links, etc. in the HTML, MarkDown, CSS and JS files:\r\n    //\r\n    // [css, js, image, movie, misc, _]\r\n    for (const type in allFiles) {\r\n        switch (type) {\r\n            case '_':\r\n                continue;\r\n            case 'markdown':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                    }\r\n                }\r\n                continue;\r\n            case 'html':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        if (key.includes('getsatisfaction-mirror/')) {\r\n                            filterHtmlOfGetsatisfactionPages(entry);\r\n                        }\r\n                    }\r\n                }\r\n                continue;\r\n            case 'css':\r\n            case 'js':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                    }\r\n                }\r\n                continue;\r\n            default:\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                    }\r\n                }\r\n                continue;\r\n        }\r\n    }\r\n    console.log('rendering site files\\' content...');\r\n    // render the HTML, MarkDown, CSS and JS files' content:\r\n    //\r\n    // [css, js, image, movie, misc, _]\r\n    for (const type in allFiles) {\r\n        switch (type) {\r\n            case '_':\r\n                continue;\r\n            case 'markdown':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        const specRec2 = await renderMD(key, md, allFiles);\r\n                        if (DEBUG >= 3)\r\n                            console.log('specRec:', showRec(specRec2));\r\n                        assert.strictEqual(specRec2, entry);\r\n                    }\r\n                }\r\n                continue;\r\n            case 'html':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        const specRec2 = await renderHTML(key, allFiles);\r\n                        if (DEBUG >= 3)\r\n                            console.log('specRec:', showRec(specRec2));\r\n                        assert.strictEqual(specRec2, entry);\r\n                    }\r\n                }\r\n                continue;\r\n            case 'css':\r\n            case 'js':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        const specRec2 = await renderFixedAssetTextFile(key, allFiles, collection);\r\n                        if (DEBUG >= 3)\r\n                            console.log('specRec:', showRec(specRec2));\r\n                        assert.strictEqual(specRec2, entry);\r\n                    }\r\n                }\r\n                continue;\r\n            default:\r\n                // we do not 'render' the binary files, right?\r\n                continue;\r\n        }\r\n    }\r\n    //\r\n    // Apply the template? Nah, that must have already happened in the render phase.\r\n    // If we have special 'generated content only' pages, such as the index page to a catalog site,\r\n    // that *still* is done through a (possibly empty, except for some metadata perhaps) `index.html`\r\n    // or README.md or other *content* file: the custom code can decide which bit of the template\r\n    // collective to apply to each page, so that would then apply a 'overview/index/landing' page\r\n    // template to such a (hypothetical) page.\r\n    //\r\n    // Hence we come to the conclusion now: every page being written is written by a (possibly empty)\r\n    // content page. If the content page is absent, the page simply is NOT generated.\r\n    //\r\n    // Meanwhile, the custom code decides which template file((s) are applied to each content item\r\n    // in the allFiles list.\r\n    //\r\n    // ---\r\n    //\r\n    // Yes, this means we'll have content pages for the 404 and other landing pages too. If they are\r\n    // absent, we do not have those landing pages. Simple as that.\r\n    //\r\n    // now render the template and postprocess all links:\r\n    console.log('Rendering page templates and extracting all internal links for mapping analysis...');\r\n    for (const type in allFiles) {\r\n        switch (type) {\r\n            case '_':\r\n            default:\r\n                continue;\r\n            case 'html':\r\n            case 'markdown':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        const destFilePath = unixify(path.join(opts.output, entry.destinationRelPath));\r\n                        if (DEBUG >= 5)\r\n                            console.log(`!!!!!!!!!!!!!!!!!!!!!!!! Type [${type}] file record: copy '${entry.path}' --> '${destFilePath}'`);\r\n                        filterHtmlHeadAfterMetadataExtraction(entry);\r\n                        // re title: frontMatter should have precedence over any other title source, including the title extracted from the document via H1\r\n                        const pathTitle = sanitizePathTotitle(path.basename(entry.relativePath, entry.ext));\r\n                        let title = (entry.metaData?.frontMatter?.title || entry.metaData?.docTitle || pathTitle).trim();\r\n                        // clean up the title:\r\n                        title = title\r\n                            .replace(/:+$/, '') // remove trailing ':' colons\r\n                            .replace(/\\s*[?]+/g, '?') // replace reams of question marks with a single '?'\r\n                            .trim();\r\n                        if (DEBUG >= 1)\r\n                            console.log('TITLE extraction:', { sourcePath: entry.relativePath, meta: entry.metaData, docTitle: entry.metaData?.docTitle, fmTitle: entry.metaData?.frontMatter?.title, pathTitle, title });\r\n                        if (title) {\r\n                            title = `<title>${title}</title>`;\r\n                        }\r\n                        else {\r\n                            title = '';\r\n                        }\r\n                        const htmlHead = entry.HtmlHead;\r\n                        const htmlBody = entry.HtmlBody;\r\n                        const originalPath = entry.relativePath;\r\n                        let fm = null;\r\n                        if (entry.metaData) {\r\n                            fm = `<pre>${JSON.stringify(entry.metaData, null, 2)}</pre>`;\r\n                        }\r\n                        const content = `\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    ${title}\n    <link href=\"https://fonts.googleapis.com/css?family=Inconsolata:400,700|Poppins:400,400i,500,700,700i&amp;subset=latin-ext\" rel=\"stylesheet\">\n    <link rel=\"stylesheet\" href=\"${entry.relativeJumpToBasePath}css/mini-default.css\">\n    <meta charset=\"utf-8\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n    ${htmlHead.html()}\n  </head>\n  <body>\n    ${fm || ''}\n\n    ${htmlBody.html()}\n\n    <footer>\n      © 2020 Qiqqa Contributors ::\n      <a href=\"https://github.com/GerHobbelt/qiqqa-open-source/blob/master/docs-src/${originalPath}\">Edit this page on GitHub</a>\n    </footer>\n  </body>\n</html>\n`.trimLeft();\r\n                        // parse rendered result page and store it for further post-processing:\r\n                        const $doc = cheerio.load(content);\r\n                        const bodyEl = $doc('body'); // implicitly created\r\n                        const headEl = $doc('head');\r\n                        // update the file record:\r\n                        entry.HtmlDocument = $doc;\r\n                        entry.HtmlBody = bodyEl;\r\n                        entry.HtmlHead = headEl;\r\n                        const linkCollection = getLinks($doc, entry.destinationRelPath);\r\n                        if (DEBUG >= 2)\r\n                            console.log('collected links for postprocessing:', { originalPath, linkCollection });\r\n                        if (DEBUG >= 3)\r\n                            console.log('update the file record after rendering the template:', { originalPath, entry: showRec(entry) });\r\n                    }\r\n                }\r\n                continue;\r\n            case 'css':\r\n            case 'js':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                    }\r\n                }\r\n                continue;\r\n        }\r\n    }\r\n    // output the files into the destination directory\r\n    console.log(`buildWebsite: command: ${command || '<no-command>'}, opts: ${JSON.stringify(opts, null, 2)}`);\r\n    // first we write the 'default' CNAME and .nojekyll files here.\r\n    // IFF the user has also provideed these, they will overwrite these ones\r\n    // in the subsequent copy/write action.\r\n    if (DEBUG >= 1)\r\n        console.log(`Copying the extra files to the website destination directory '${config.destinationPath}'...`);\r\n    await mdGenerated(config.destinationPath);\r\n    // now write the CSS, HTML, JS and other files:\r\n    console.log(`Writing all processed & collected files to the website destination directory '${config.destinationPath}'...`);\r\n    for (const type in allFiles) {\r\n        switch (type) {\r\n            case '_':\r\n                continue;\r\n            case 'html':\r\n            case 'markdown':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        const destFilePath = unixify(path.join(opts.output, entry.destinationRelPath));\r\n                        if (DEBUG >= 5)\r\n                            console.log(`!!!!!!!!!!!!!!!!!!!!!!!! Type [${type}] file record: copy '${entry.path}' --> '${destFilePath}'`);\r\n                        const dstDir = unixify(path.dirname(destFilePath));\r\n                        fs.mkdirSync(dstDir, { recursive: true });\r\n                        const content = '<!DOCTYPE html>\\n' + entry.HtmlDocument.html();\r\n                        fs.writeFileSync(destFilePath, content, 'utf8');\r\n                    }\r\n                }\r\n                continue;\r\n            case 'css':\r\n            case 'js':\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        const destFilePath = unixify(path.join(opts.output, entry.destinationRelPath));\r\n                        if (DEBUG >= 5)\r\n                            console.log(`!!!!!!!!!!!!!!!!!!!!!!!! Type [${type}] file record: copy '${entry.path}' --> '${destFilePath}'`);\r\n                        const dstDir = unixify(path.dirname(destFilePath));\r\n                        fs.mkdirSync(dstDir, { recursive: true });\r\n                        fs.writeFileSync(destFilePath, entry.RawContent, 'utf8');\r\n                    }\r\n                }\r\n                continue;\r\n            default:\r\n                {\r\n                    const collection = allFiles[type];\r\n                    for (const slot of collection) {\r\n                        const key = slot[0];\r\n                        const entry = slot[1];\r\n                        const destFilePath = unixify(path.join(opts.output, entry.destinationRelPath));\r\n                        if (DEBUG >= 5)\r\n                            console.log(`!!!!!!!!!!!!!!!!!!!!!!!! Type [${type}] file record: copy '${entry.path}' --> '${destFilePath}'`);\r\n                        const dstDir = unixify(path.dirname(destFilePath));\r\n                        fs.mkdirSync(dstDir, { recursive: true });\r\n                        fs.copyFileSync(entry.path, destFilePath, fs.constants.COPYFILE_FICLONE);\r\n                    }\r\n                }\r\n                continue;\r\n        }\r\n    }\r\n}\r\n// compile the MarkDown files to a token stream. Belay *rendering* until all files, including the HTML files out there,\r\n// have been processed as we will be patching some tokens in there before the end is neigh!\r\nasync function compileMD(mdPath, md, allFiles) {\r\n    if (DEBUG >= 3)\r\n        console.log(`processing file: ${mdPath}...`);\r\n    return new Promise((resolve, reject) => {\r\n        fs.readFile(mdPath, {\r\n            encoding: 'utf8'\r\n        }, async (err, data) => {\r\n            if (err) {\r\n                reject(new Error(`ERROR: read error ${err} for file ${mdPath}`));\r\n                return;\r\n            }\r\n            const env = {\r\n                getIncludeRootDir: null,\r\n                title: null\r\n            };\r\n            if (DEBUG >= 8)\r\n                console.log(`source: length: ${data.length}`);\r\n            // augment the md instance for use with the markdown_it_include plugin:\r\n            env.getIncludeRootDir = function (options, state, startLine, endLine) {\r\n                if (DEBUG >= 6)\r\n                    console.log('##### include root dir is today:', { dir: path.dirname(mdPath) });\r\n                return path.dirname(mdPath);\r\n            };\r\n            // let content = md.render(data); --> .parse + .renderer.render\r\n            //\r\n            // .parse --> new state + process: return tokens\r\n            // let tokens = md.parse(data, env)\r\n            const state = new md.core.State(data, md, env);\r\n            md.core.process(state);\r\n            const tokens = state.tokens;\r\n            const metadata = {\r\n                frontMatter: null,\r\n                docTitle: null\r\n            };\r\n            if (DEBUG >= 10)\r\n                console.log('tokens:\\n', limitDebugOutput(JSON.stringify(cleanTokensForDisplay(tokens), null, 2)));\r\n            const typeMap = new Set();\r\n            traverseTokens(tokens, (t, idx, arr, depth) => {\r\n                typeMap.add(t.type);\r\n                markdownTokens[t.type] = true;\r\n                if (t.type === 'front_matter') {\r\n                    metadata.frontMatter = t.meta;\r\n                }\r\n            });\r\n            if (DEBUG >= 4)\r\n                console.log('token types:', typeMap);\r\n            if (0) {\r\n                let position = 0;\r\n                let prevToken = null;\r\n                traverseTokens(tokens, (t, idx, arr, depth) => {\r\n                    if (!Number.isFinite(t.position)) {\r\n                        console.error('erroneous token position:', t);\r\n                        return;\r\n                    }\r\n                    if (!Number.isFinite(t.size)) {\r\n                        console.error('erroneous token size:', t);\r\n                        return;\r\n                    }\r\n                    if (t.position >= position) {\r\n                        position = t.position;\r\n                    }\r\n                    else {\r\n                        console.warn('token position is dropping back / reversing:', { position, t, prevToken });\r\n                    }\r\n                    prevToken = t;\r\n                });\r\n            }\r\n            if (env.title) {\r\n                metadata.docTitle = env.title.trim();\r\n            }\r\n            // update the file record:\r\n            const el = allFiles.markdown.get(mdPath);\r\n            if (DEBUG >= 3)\r\n                console.log('update the file record:', { mdPath, el: showRec(el) });\r\n            el.mdState = state;\r\n            el.mdEnv = env;\r\n            el.mdTypeMap = typeMap;\r\n            el.metaData = metadata;\r\n            resolve(el);\r\n        });\r\n    });\r\n}\r\n// compile the MarkDown files to a token stream. Belay *rendering* until all files, including the HTML files out there,\r\n// have been processed as we will be patching some tokens in there before the end is neigh!\r\nasync function renderMD(mdPath, md, allFiles) {\r\n    if (DEBUG >= 3)\r\n        console.log(`processing file: ${mdPath}...`);\r\n    return new Promise((resolve, reject) => {\r\n        const el = allFiles.markdown.get(mdPath);\r\n        const state = el.mdState;\r\n        const env = el.mdEnv;\r\n        const typeMap = el.mdTypeMap;\r\n        const metadata = el.metaData;\r\n        const tokens = state.tokens;\r\n        const content = md.renderer.render(tokens, md.options, env);\r\n        if (DEBUG >= 4)\r\n            console.log('output:\\n', limitDebugOutput(content));\r\n        const $doc = cheerio.load('<html><head><body>\\n' + content);\r\n        const bodyEl = $doc('body'); // implicitly created\r\n        const headEl = $doc('head');\r\n        if (DEBUG >= 5)\r\n            console.log('MARKDOWN:\\n', showRec({ html: $doc, body: bodyEl.html(), head: headEl.html() }));\r\n        // update the file record:\r\n        if (DEBUG >= 3)\r\n            console.log('update the file record:', { mdPath, el: showRec(el) });\r\n        el.HtmlDocument = $doc;\r\n        el.HtmlBody = bodyEl;\r\n        el.HtmlHead = headEl;\r\n        el.metaData = metadata;\r\n        resolve(el);\r\n    });\r\n}\r\n// compile the HTML files to a DOM token stream. Belay *rendering* until all files, including the MarkDown files out there,\r\n// have been processed as we will be patching some DOM nodes in there before the end is neigh!\r\nasync function loadHTML(htmlPath, allFiles) {\r\n    if (DEBUG >= 3)\r\n        console.log(`processing file: ${htmlPath}...`);\r\n    return new Promise((resolve, reject) => {\r\n        fs.readFile(htmlPath, {\r\n            encoding: 'utf8'\r\n        }, async (err, data) => {\r\n            if (err) {\r\n                reject(new Error(`ERROR: read error ${err} for file ${htmlPath}`));\r\n                return;\r\n            }\r\n            if (DEBUG >= 8)\r\n                console.log(`source: length: ${data.length}`);\r\n            const $doc = cheerio.load(data);\r\n            const bodyEl = $doc('body'); // implicitly created\r\n            const headEl = $doc('head');\r\n            const titleEl = headEl.find('title');\r\n            const title = titleEl.html()?.trim();\r\n            if (DEBUG >= 3)\r\n                console.log('HTML:\\n', showRec({ html: $doc, body: bodyEl.html(), head: headEl.html() }));\r\n            // update the file record:\r\n            const el = allFiles.html.get(htmlPath);\r\n            el.HtmlDocument = $doc;\r\n            el.HtmlBody = bodyEl;\r\n            el.HtmlHead = headEl;\r\n            if (title) {\r\n                el.metaData = {\r\n                    docTitle: title\r\n                };\r\n            }\r\n            resolve(el);\r\n        });\r\n    });\r\n}\r\n// remove any HTML DOM elements from the <head> section which would otherwise collide with the standard metadata.\r\nfunction filterHtmlHeadAfterMetadataExtraction(entry) {\r\n    const $doc = entry.HtmlDocument;\r\n    const headEl = $doc('head');\r\n    const titleEl = headEl.find('title');\r\n    titleEl?.remove();\r\n}\r\nfunction filterHtmlOfGetsatisfactionPages(entry) {\r\n    const $doc = entry.HtmlDocument;\r\n    const headEl = $doc('head');\r\n    if (DEBUG >= 2)\r\n        console.log('getsatis filtering:', { headEl, children: headEl.children() });\r\n    // delete all <script> elements anywhere in there:\r\n    $doc('script').remove();\r\n    // kill the <base> tag too\r\n    headEl.find('base').remove();\r\n    // kill RSS link, etc.\r\n    const metalist = [\r\n        'type=\"application/rss+xml\"',\r\n        'property=\"fb:admins\"',\r\n        'name=\"csrf-param\"',\r\n        'name=\"csrf-token\"',\r\n        /*\r\n    <meta content=\"website\" property=\"og:type\">\r\n    <meta content=\"https://getsatisfaction.com/qiqqa/topics/-helloooo\" property=\"og:url\">\r\n    <meta content=\"https://getsatisfaction.com/assets/question_med.png\" property=\"og:image\">\r\n    <meta content=\"Qiqqa.com\" property=\"og:site_name\">\r\n         */\r\n        'property=\"og:type\"',\r\n        'property=\"og:url\"',\r\n        'property=\"og:image\"',\r\n        'property=\"og:site_name\"',\r\n        // https://api.jquery.com/category/selectors/\r\n        // kill one of the style sheets at least\r\n        'href*=\"assets/employee_tools\"'\r\n    ];\r\n    metalist.forEach(prop => {\r\n        headEl.find(`[${prop}]`).remove();\r\n    });\r\n    headEl.find('link[rel=\"shortcut icon\"]').remove();\r\n    const kill_list = [\r\n        '#header_search_topic',\r\n        'div[style*=\"left: -10000px;\"]',\r\n        '.crumb_select',\r\n        // kill all the <style> blobs and CSS loads too:\r\n        'style',\r\n        'link[type=\"text/css\"]',\r\n        '#overlay',\r\n        '#followable_dropdown',\r\n        '#mini_profile'\r\n    ];\r\n    kill_list.forEach(prop => {\r\n        $doc(prop).remove();\r\n    });\r\n    const kill_attr_list = [\r\n        'onclick',\r\n        'onmouseover',\r\n        'onmouseout'\r\n    ];\r\n    kill_attr_list.forEach(prop => {\r\n        $doc(`[${prop}]`).removeAttr(prop);\r\n    });\r\n    // nuke the head comment blocks (old IEE stuff, etc.)\r\n    let node = headEl.children()[0];\r\n    while (node != null) {\r\n        if (node.type === 'comment') {\r\n            // HACK: turn this into an empty 'text' node instead!\r\n            const tn = node; // shut up TypeScript too...\r\n            tn.type = 'text';\r\n            tn.data = '';\r\n        }\r\n        node = node.next;\r\n    }\r\n    //console.log('getsatis filtering done:', { html: $doc.html(), children: headEl.children(), head: headEl.html() });\r\n}\r\n// compile the HTML files to a DOM token stream. Belay *rendering* until all files, including the MarkDown files out there,\r\n// have been processed as we will be patching some DOM nodes in there before the end is neigh!\r\nasync function renderHTML(htmlPath, allFiles) {\r\n    if (DEBUG >= 3)\r\n        console.log(`processing file: ${htmlPath}...`);\r\n    return new Promise((resolve, reject) => {\r\n        const el = allFiles.html.get(htmlPath);\r\n        const $doc = el.HtmlDocument;\r\n        const bodyEl = el.HtmlBody;\r\n        const headEl = el.htmlHead;\r\n        if (DEBUG >= 3)\r\n            console.log('HTML:\\n', showRec({ html: $doc, body: bodyEl.html(), head: headEl.html() }));\r\n        // update the file record:\r\n        resolve(el);\r\n    });\r\n}\r\nasync function loadFixedAssetTextFile(filePath, allFiles, collection) {\r\n    if (DEBUG >= 3)\r\n        console.log(`processing file: ${filePath}...`);\r\n    return new Promise((resolve, reject) => {\r\n        fs.readFile(filePath, {\r\n            encoding: 'utf8'\r\n        }, async (err, data) => {\r\n            if (err) {\r\n                reject(new Error(`ERROR: read error ${err} for file ${filePath}`));\r\n                return;\r\n            }\r\n            if (DEBUG >= 8)\r\n                console.log(`source: length: ${data.length}`);\r\n            // update the file record:\r\n            const el = collection.get(filePath);\r\n            el.RawContent = data;\r\n            resolve(el);\r\n        });\r\n    });\r\n}\r\nasync function renderFixedAssetTextFile(filePath, allFiles, collection) {\r\n    if (DEBUG >= 3)\r\n        console.log(`processing file: ${filePath}...`);\r\n    return new Promise((resolve, reject) => {\r\n        // update the file record:\r\n        const el = collection.get(filePath);\r\n        //el.RawContent = data;\r\n        resolve(el);\r\n    });\r\n}\r\nasync function loadFixedAssetBinaryFile(filePath, allFiles, collection) {\r\n    if (DEBUG >= 3)\r\n        console.log(`processing file: ${filePath}...`);\r\n    // We DO NOT load binary files as that would only clutter the nodeJS heap memory and cause out-of-memory exceptions.\r\n    return new Promise((resolve, reject) => {\r\n        const x = fs.existsSync(filePath);\r\n        if (!x) {\r\n            reject(new Error(`ERROR: file '${filePath}' does not exist.`));\r\n            return;\r\n        }\r\n        //if (DEBUG >= 8) console.log(`source: length: ${data.length}`);\r\n        // update the file record:\r\n        const el = collection.get(filePath);\r\n        //el.RawContent = data;\r\n        el.contentIsBinary = true;\r\n        resolve(el);\r\n    });\r\n}\r\nfunction cleanTokensForDisplay(tokens) {\r\n    const rv = [];\r\n    for (const i in tokens) {\r\n        let t = tokens[i];\r\n        t = cleanSingleTokenForDisplay(t);\r\n        if (t.children) {\r\n            t.children = cleanTokensForDisplay(t.children);\r\n        }\r\n        rv[i] = t;\r\n    }\r\n    return rv;\r\n}\r\nfunction cleanSingleTokenForDisplay(token) {\r\n    const rv = {};\r\n    for (const attr in token) {\r\n        if (token[attr] !== '' && token[attr] != null) {\r\n            rv[attr] = token[attr];\r\n        }\r\n    }\r\n    return rv;\r\n}\r\nasync function mdGenerated(pagePaths) {\r\n    // cp docs-src/.nojekyll docs/ && cp docs-src/CNAME docs/\r\n    console.log('async generated HIT');\r\n    fs.writeFileSync(absDstPath('CNAME'), 'qiqqa.org\\n', 'utf8');\r\n    fs.writeFileSync(absDstPath('.nojekyll'), '');\r\n}\r\nfunction traverseTokens(tokens, cb, depth) {\r\n    depth = depth || 0;\r\n    for (let i = 0, len = tokens.length; i < len; i++) {\r\n        const t = tokens[i];\r\n        cb(t, i, tokens, depth);\r\n        if (t.children) {\r\n            traverseTokens(t.children, cb, depth + 1);\r\n        }\r\n    }\r\n}\r\n// demo()\r\n//   .then(() => {\r\n//      console.log('done');\r\n//   })\r\n//   .catch(err => {\r\n//     console.error('error:', err);\r\n//   });\r\n//# sourceMappingURL=index.js.map"],"names":[],"mappings":";;;;;;;;;;;;;;AAAA;AAMA,gBAAgB,CAAC,OAAjB;;AAaA,MAAM,UAAU,GAAG,aAAa,CAAC,MAAM,CAAC,IAAP,CAAY,GAAb,CAAhC;;AACA,MAAM,SAAS,GAAG,IAAI,CAAC,OAAL,CAAa,UAAb,CAAlB;;AAEA,MAAM,GAAG,GAAG,IAAI,CAAC,KAAL,CAAW,EAAE,CAAC,YAAH,CAAgB,IAAI,CAAC,SAAL,CAAe,IAAI,CAAC,IAAL,CAAU,SAAV,EAAqB,iBAArB,CAAf,CAAhB,EAAyE,MAAzE,CAAX,CAAZ;AAWA,IAAI,KAAK,GAAG,CAAZ;AAkIc,SAAU,IAAV,GAAc;AAC1B,EAAA,MAAM,CAAC,MAAP,CAAc,UAAd;AAEA,EAAA,MAAM,CACH,OADH,CACW,OADX,EAEG,MAFH,CAEU,OAFV,EAEmB;AACf,IAAA,IAAI,EAAE,GADS;AAEf,IAAA,IAAI,EAAE,KAFS;AAGf,eAAW,CAHI;AAIf,IAAA,IAAI,EAAE;AAJS,GAFnB,EAQG,MARH,CAQU,QARV,EAQoB;AAChB,IAAA,IAAI,EAAE,GADU;AAEhB,eAAW,WAFK;AAGhB,IAAA,IAAI,EAAE;AAHU,GARpB,EAaG,MAbH,CAaU,QAbV,EAaoB;AAChB,IAAA,IAAI,EAAE,GADU;AAEhB,IAAA,IAAI,EAAE,KAFU;AAGhB,IAAA,IAAI,EAAE;AAHU,GAbpB,EAkBG,QAlBH,CAkBY,gBAAgB,IAAhB,EAAsB,GAAtB,EAAyB;AACjC,QAAI;AACF,YAAM,YAAY,CAAC,IAAD,EAAO,GAAP,CAAlB;AACD,KAFD,CAEE,OAAO,EAAP,EAAW;AACX,MAAA,OAAO,CAAC,KAAR,CAAc,UAAU,EAAE,CAAC,OAAO,kBAAlC;AACA,MAAA,OAAO,CAAC,KAAR,CAAc,EAAd;AACA,MAAA,OAAO,CAAC,IAAR,CAAa,CAAb;AACD;AACF,GA1BH,EA2BG,IA3BH,CA2BQ,4BA3BR;AA6BA,EAAA,MAAM,CACH,OADH,CACW,QADX,EAEG,MAFH,CAEU,OAFV,EAEmB;AACf,IAAA,IAAI,EAAE,GADS;AAEf,IAAA,IAAI,EAAE,KAFS;AAGf,IAAA,IAAI,EAAE;AAHS,GAFnB,EAOG,MAPH,CAOU,QAPV,EAOoB;AAChB,IAAA,IAAI,EAAE,GADU;AAEhB,eAAW,WAFK;AAGhB,IAAA,IAAI,EAAE;AAHU,GAPpB,EAYG,MAZH,CAYU,SAZV,EAYqB;AACjB,IAAA,IAAI,EAAE,GADW;AAEjB,IAAA,IAAI,EAAE;AAFW,GAZrB,EAgBG,QAhBH,CAgBY,UAAU,IAAV,EAAgB,GAAhB,EAAmB;AAC3B,QAAI;AACF,MAAA,WAAW,CAAC,IAAD,EAAO,GAAP,CAAX;AACD,KAFD,CAEE,OAAO,EAAP,EAAW;AACX,MAAA,OAAO,CAAC,KAAR,CAAc,UAAU,EAAE,CAAC,OAAO,mBAAmB,EAAE,EAAvD;AACA,MAAA,OAAO,CAAC,IAAR,CAAa,CAAb;AACD;AACF,GAvBH,EAwBG,IAxBH,CAwBQ,sBAxBR;AA0BA,EAAA,MAAM,CACH,SADH,GAEG,MAFH,CAEU,OAFV,EAEmB;AACf,IAAA,IAAI,EAAE,GADS;AAEf,IAAA,IAAI,EAAE,KAFS;AAGf,eAAW,CAHI;AAIf,IAAA,IAAI,EAAE;AAJS,GAFnB,EAQG,MARH,CAQU,QARV,EAQoB;AAChB,IAAA,IAAI,EAAE,GADU;AAEhB,eAAW,WAFK;AAGhB,IAAA,IAAI,EAAE;AAHU,GARpB,EAaG,MAbH,CAaU,SAbV,EAaqB;AACjB,IAAA,IAAI,EAAE,IADW;AAEjB,IAAA,IAAI,EAAE,wBAFW;AAGjB,IAAA,QAAQ,EAAE,YAAA;AACR,aAAO,WAAW,GAAG,CAAC,OAAO,EAA7B;AACD;AALgB,GAbrB,EAoBG,QApBH,CAoBY,UAAU,IAAV,EAAgB,GAAhB,EAAmB;AAC3B,QAAI;AACF,MAAA,YAAY,CAAC,IAAD,EAAO,GAAP,CAAZ;AACD,KAFD,CAEE,OAAO,EAAP,EAAW;AACX,MAAA,OAAO,CAAC,KAAR,CAAc,UAAU,EAAE,CAAC,OAAO,mBAAmB,EAAE,EAAvD;AACA,MAAA,OAAO,CAAC,IAAR,CAAa,CAAb;AACD;AACF,GA3BH;AA6BA,EAAA,MAAM,CAAC,KAAP;AACD;;AAQD,SAAS,OAAT,CAAiB,IAAjB,EAA8B;AAC5B,SAAO,IAAI,CAAC,OAAL,CAAa,KAAb,EAAoB,GAApB,CAAP;AACD;;AAmXD,eAAe,gBAAf,CAAgC,YAAhC,EAAqD;AACnD,MAAI,YAAJ,EAAkB;AAChB;AACA,QAAI,KAAK,IAAI,CAAb,EAAiB,OAAO,CAAC,GAAR,CAAY,oBAAoB,YAAY,GAA5C;;AACjB,QAAI,CAAC,IAAI,CAAC,UAAL,CAAgB,YAAhB,CAAL,EAAoC;AAClC;AACA,MAAA,YAAY,GAAG,OAAO,CAAC,IAAI,CAAC,IAAL,CAAU,OAAO,CAAC,GAAR,EAAV,EAAyB,YAAzB,CAAD,CAAtB;AACD;;AACD,QAAI,KAAK,IAAI,CAAb,EAAiB,OAAO,CAAC,GAAR,CAAY,8BAA8B,YAAY,IAAtD;;AACjB,QAAI;AACF,YAAM,UAAU,GAAG,MAAM,OAAO,YAAa,YAApB,CAAzB;AACA,YAAM,CAAN;AACA,aAAO,UAAP;AACD,KAJD,CAIE,OAAO,GAAP,EAAY;AACZ,MAAA,OAAO,CAAC,KAAR,CAAc,kBAAd,EAAkC,GAAlC,EADY;;AAGZ,YAAM,IAAI,KAAJ,CAAU,wCAAwC,YAAY,aAAa,GAAG,EAA9E,CAAN;AACD;AACF,GAjBD,MAiBO;AACL,WAAO,IAAI,OAAJ,CAAY,CAAC,OAAD,EAAU,MAAV,KAAoB;AACrC,YAAM,UAAU,GAAG;AACjB,QAAA,OAAO,EAAE,SAAS,GAAT,GAAY;AAEpB;AAHgB,OAAnB;AAKA,MAAA,OAAO,CAAC,UAAD,CAAP;AACD,KAPM,CAAP;AAQD;AACF;;AAED,eAAe,WAAf,CAA2B,IAA3B,EAAiC,OAAjC,EAAwC;AACtC,EAAA,OAAO,CAAC,GAAR,CACE,yBAAyB,OAAO,IAAI,cAAc,WAAW,IAAI,CAAC,SAAL,CAC3D,IAD2D,EAE3D,IAF2D,EAG3D,CAH2D,CAI5D,EALH;AAQA,EAAA,KAAK,GAAG,IAAI,CAAC,GAAL,CAAS,KAAT,EAAgB,MAAM,CAAC,QAAP,CAAgB,CAAC,IAAI,CAAC,KAAtB,IAA+B,CAAC,IAAI,CAAC,KAArC,GAA6C,IAAI,CAAC,KAAL,GAAa,CAAb,GAAiB,CAA9E,CAAR;AACA,EAAA,OAAO,CAAC,GAAR,CAAY,UAAZ,EAAwB,KAAxB;AAEA,SAAO,IAAI,OAAJ,CAAY,CAAC,OAAD,EAAU,MAAV,KAAoB;AACrC,IAAA,OAAO,CAAC,CAAD,CAAP;AACD,GAFM,CAAP;AAGD;;AAuBD,eAAe,YAAf,CAA4B,IAA5B,EAAkC,OAAlC,EAAyC;AACvC,EAAA,OAAO,CAAC,GAAR,CACE,0BAA0B,OAAO,IAAI,cAAc,WAAW,IAAI,CAAC,SAAL,CAC5D,IAD4D,EAE5D,IAF4D,EAG5D,CAH4D,CAI7D,EALH;AAQA,EAAA,KAAK,GAAG,IAAI,CAAC,GAAL,CAAS,KAAT,EAAgB,MAAM,CAAC,QAAP,CAAgB,CAAC,IAAI,CAAC,KAAtB,IAA+B,CAAC,IAAI,CAAC,KAArC,GAA6C,IAAI,CAAC,KAAL,GAAa,CAAb,GAAiB,CAA9E,CAAR;AACA,EAAA,OAAO,CAAC,GAAR,CAAY,UAAZ,EAAwB,KAAxB;;AAEA,QAAM,KAAK,GAAG,IAAI,CAAC,CAAL,CAAO,KAAP,CAAa,OAAO,GAAG,CAAH,GAAO,CAA3B,CAAd;;AACA,QAAM,aAAa,GAAG,CAAtB;AACA,EAAA,OAAO,CAAC,GAAR,CAAY,iBAAZ,EAA+B,KAA/B;;AAEA,MAAI,CAAC,KAAD,IAAU,KAAK,CAAC,MAAN,GAAe,aAA7B,EAA4C;AAC1C,UAAM,IAAI,KAAJ,CACJ,6EADI,CAAN;AAGD,GApBsC;;;AAuBvC,MAAI,YAAY,GAAG,IAAI,CAAC,MAAxB,CAvBuC;AA0BvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,MAAI,CAAC,IAAI,CAAC,UAAL,CAAgB,YAAhB,CAAL,EAAoC;AAClC,UAAM,aAAa,GAAG,CACpB,OAAO,CAAC,IAAI,CAAC,IAAL,CAAU,KAAK,CAAC,CAAD,CAAf,EAAoB,WAApB,CAAD,CADa,EAEpB,OAAO,CAAC,IAAI,CAAC,IAAL,CAAU,OAAO,CAAC,GAAR,EAAV,EAAyB,WAAzB,CAAD,CAFa,EAGpB,OAAO,CAAC,KAAK,CAAC,CAAD,CAAN,CAHa,EAIpB,OAAO,CAAC,OAAO,CAAC,GAAR,EAAD,CAJa,CAAtB;;AAOA,SAAK,IAAI,CAAT,IAAc,aAAd,EAA6B;AAC3B,UAAI,OAAO,GAAG,OAAO,CAAC,IAAI,CAAC,IAAL,CAAU,CAAV,EAAa,YAAb,CAAD,CAArB;AACA,UAAI,KAAK,IAAI,CAAb,EAAgB,OAAO,CAAC,GAAR,CAAY,cAAe,OAAQ,mBAAnC;;AAChB,UAAI,EAAE,CAAC,UAAH,CAAc,OAAd,CAAJ,EAA4B;AAC1B,QAAA,YAAY,GAAG,OAAf;AACA;AACD;AACF;AACF;;AAED,MAAI,UAAU,GAAG,IAAjB;;AACA,MAAI;AACF,IAAA,UAAU,GAAG,MAAM,gBAAgB,CAAC,YAAD,CAAnC;AACD,GAFD,CAEE,OAAO,GAAP,EAAY;AACZ,IAAA,OAAO,CAAC,KAAR,CAAc,4FAAd,EAA4G,GAA5G;AACA,IAAA,UAAU,GAAG,MAAM,gBAAgB,CAAC,IAAD,CAAnC;AACD;;AACD,MAAI,KAAK,IAAI,CAAb,EAAgB,OAAO,CAAC,GAAR,CAAY,2BAAZ,EAAyC,UAAzC;AAChB,EAAA,MAAM,CAAC,UAAU,CAAC,OAAX,IAAsB,IAAvB,CAAN;AACA,EAAA,MAAM,CAAC,OAAO,UAAU,CAAC,OAAlB,KAA8B,UAA/B,EAA2C,iBAAiB,YAAY,iEAAxE,CAAN;AACA,MAAI,KAAK,IAAI,CAAb,EAAgB,OAAO,CAAC,GAAR,CAAY,4BAAZ,EAA0C,UAA1C;AAEhB,MAAI,mBAAmB,GAAG,KAAK,CAAC,CAAD,CAA/B,CAjEuC;;AAmEvC,MAAI,CAAC,IAAI,CAAC,UAAL,CAAgB,mBAAhB,CAAL,EAA2C;AACzC,IAAA,mBAAmB,GAAG,IAAI,CAAC,IAAL,CAAU,OAAO,CAAC,GAAR,EAAV,EAAyB,mBAAzB,CAAtB;AACD;;AACD,EAAA,mBAAmB,GAAG,OAAO,CAAC,IAAI,CAAC,SAAL,CAAe,mBAAf,CAAD,CAA7B;AACA,MAAI,KAAK,IAAI,CAAb,EAAgB,OAAO,CAAC,GAAR,CAAY,wBAAZ,EAAsC,mBAAtC;AAEhB,EAAiB,EAAE,CAAC,SAAH,CAAa,mBAAb;AAEjB,QAAM,CAAN;AAilCD;AAocD;AACA;AACA;AACA;AACA;AACA;;;;"}